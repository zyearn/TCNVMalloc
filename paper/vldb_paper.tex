% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)

\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


\begin{document}

% ****************** TITLE ****************************************

\title{A Sample {\ttlit Proceedings of the VLDB Endowment} Paper in LaTeX
Format\titlenote{for use with vldb.cls}}

% possible, but not really needed or used for PVLDB:
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as\textit{Author's Guide to Preparing ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and BibTeX} at \texttt{www.acm.org/eaddress.htm}}}

% ****************** AUTHORS **************************************

% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{8} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Ben Trovato\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{1932 Wallamaloo Lane}\\
       \affaddr{Wallamaloo, New Zealand}\\
       \email{trovato@corporation.com}
% 2nd. author
\alignauthor
G.K.M. Tobin\titlenote{The secretary disavows
any knowledge of this author's actions.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{P.O. Box 1212}\\
       \affaddr{Dublin, Ohio 43017-6221}\\
       \email{webmaster@marysville-ohio.com}
% 3rd. author
\alignauthor Lars Th{\Large{\sf{\o}}}rv{$\ddot{\mbox{a}}$}ld\titlenote{This author is the
one who did all the really hard work.}\\
       \affaddr{The Th{\large{\sf{\o}}}rv{$\ddot{\mbox{a}}$}ld Group}\\
       \affaddr{1 Th{\large{\sf{\o}}}rv{$\ddot{\mbox{a}}$}ld Circle}\\
       \affaddr{Hekla, Iceland}\\
       \email{larst@affiliation.org}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor Lawrence P. Leipuner\\
       \affaddr{Brookhaven Laboratories}\\
       \affaddr{Brookhaven National Lab}\\
       \affaddr{P.O. Box 5000}\\
       \email{lleipuner@researchlabs.org}
% 5th. author
\alignauthor Sean Fogarty\\
       \affaddr{NASA Ames Research Center}\\
       \affaddr{Moffett Field}\\
       \affaddr{California 94035}\\
       \email{fogartys@amesres.org}
% 6th. author
\alignauthor Charles Palmer\\
       \affaddr{Palmer Research Laboratories}\\
       \affaddr{8600 Datapoint Drive}\\
       \affaddr{San Antonio, Texas 78229}\\
       \email{cpalmer@prl.com}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\additionalauthors{Additional authors: John Smith (The Th{\o}rv\"{a}ld Group, {\texttt{jsmith@affiliation.org}}), Julius P.~Kumquat
(The \raggedright{Kumquat} Consortium, {\small \texttt{jpkumquat@consortium.net}}), and Ahmet Sacan (Drexel University, {\small \texttt{ahmetdevel@gmail.com}})}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.


\maketitle

\begin{abstract}
The abstract for your paper for the PVLDB Journal submission.
The template and the example document are based on the ACM SIG Proceedings  templates. This file is part of a package for preparing the submissions for review. These files are in the camera-ready format, but they do not contain the full copyright note.
Note that after the notification of acceptance, there will be an updated style file for the camera-ready submission containing the copyright note.
\end{abstract}



\section{Introduction}

Dynamic random-access memory(DRAM) has been used as the main memory of computer system for a long time, which is a type of random-access memory that stores each bit of data in a separate capacitor within an integrated circuit. 
However, with the great demand of performance and enerygy-constrain application, the defects of DRAM has become a main concern, for example, the limited density and its high energy consumption. 
In order to address these problems, an emerging new technology named non-volatile memory(NVM) has been proposed, such as Phase-change memory(PCM), spin torque, and memristor. 
NVM has the advantages of low latency, low power consumption and byte-addressable, which makes it a better alternative when compared  to DRAM.

However, some non-volatile memories suffers from limited write endurance. 
Let we take PCM as example. A typical PCM cell permanently fails after nearly $10^7$ to $10^9$ writes. 
In such circumstance, some write-intensive applications will break the PCM in a short time. 
Moreover, many hardware-level wear-awareness policies have been proposed. 
But the popularization of these specified hardware is much slower than the popularization of NVM in the near future. 
What’s more worse, the legacy hardware system then can not use NVM. 
In order to tackle ``write-too-intensive'' problem and support a software-level wear-aware memory allocator, a new memory allocator targeted for NVM platform must be designed and used in nowadays’ applications running on NVM.

Moreover, present wear-aware allocators without hardware-level wear-leveling also don’t support global wear-leveling. 
For example, if an application calls malloc-like interface to get a writeable PCM address, excessive writes to this PCM cell can rapidly destroy it. 
This is not the thing that a memory allocator can control without explicit hardware modifications. It remains a problem we must solve otherwise PCM will be damaged much earlier than we expect.

In this paper, we propose a wear-aware allocator that provide wear-awareness without degrading the performance of allocator compared with state-of-the art allocator. 
Specifically, tcwamalloc concerns three main folds of metadata memory write-reduction, thread arenas with a dedicated wear-aware allocation policy and APIs to support global. 
First, it decouples metadata and data management. Generally speaking, putting metadata into DRAM will decrease plenty of writes to NVM. 
Besides, we provide a wear-aware memory allocation policy without degrading the performance when compared to other NVM and DRAM allocators. 
At last, tcwamalloc implement a mechanisms that allow users do the global wear-leveling without the help of modifications in hardware.

Our contributions can be summarized as follows:
\begin{enumerate}
    \item metadata %分离
    \item % 粗细粒度结合的wear, wait-free(后台线程来把list中的chunk放入优先级队列)
    \item global API wear
    \item experiment...
\end{enumerate}

We have implemented a prototype version of tcwamalloc and evaluated its performance and some critical aspects against state-of-the-art memory allocators. 
Experiment shows that for most cases tcwamalloc outperforms prior system in average block allocation times and allocation latency.

\section{Background and Motivations}

不用用glibc，因为重用
用USING, WAITING 代替 fore，back
[img] NVRAM在系统中的位置

\section{Design of tcwamalloc}

In this section, we propose tcwamalloc, an memory allocator for non-volatile memory with the dedicated design for wear-aware purpose without the descend of allocation performace.

\subsection{Design Principles}

The most important design goal of tcnvmalloc is wear-levelling. 
Hence, every time we call tcwamalloc’s API to gain a writeable address, 
a memory block with least allocation times is expected to return to us. 
However, a strict policy which return the exact block with least allocation times may introduce extra time penalty.
ln the later section will see a great tradeoff to tackle this problem.

Another requirement is low latency,
otherwise the memory would probably become the bottleneck of the entire program, 
which results in the allocator to be useless. 
To reduce the allocation latency, a local heap should be used by every thread to reduce the possible lock contention,
and all memory managed by thread local heap should be allocated from a global heap.
however, using lock when request/free memory from global heap is inevitable,
as we will see, this is the only lock we use in the whole allocator.

\subsection{Overview Stucture}

In this section, we will dig deeper into the design architecture of tcwamalloc.
The stucture of tcwamalloc is showed in Figure xx.
tcwamalloc maintains a local heap for each thread, and a global heap for all threads.
The reason why we use such a design is from the obvious observation that if a request from a thread can be satisfied by its local heap,
the allocation latency will be very low since there is no lock contention which may degrade the performance.
However, there must be a global heap that manage all the memory that maintained by each thread,
therefore a lock must be involved. One of our implementation focus is emphasized on how to reduce the use of lock to the best of our ability.

[img]overall architecture

Each local heap contains several fix-sized memory chunk.
Each memory chunk is further divided into several memory block according to the size class.
Each thread maintains an array of in-use memory chunk, an array of list that contains a list of waiting chunk and a free list to hold empty chunk.
When a thread makes a memory request of some certain memory class and there is no corresponding in-use chunk to answer that request,
the corresponding chunk in waiting list is examined to become a in-use chunk. 
If still no usable memory chunks can be found,
the free list in the local heap or global heap will be visited based on our wear-aware policy,
which will be discussed in the further subsection.

\subsection{Memory Chunk}

Memory chunk is the basic building block that would be transferred between global heap and local heap. 
A memory chunk consists of two parts: a small chunk header and a 64KB chunk body. 
Chunk body is divided into several memory block based on the size class,
obviously, with smaller size class comes more memory blocks. 
Chunk header stores some metadata such as remaining free blocks number, size class, chunk owner and so on.

% classes of allocatable objects
\subsubsection{Classes of allocatable blocks}
Since a memory chunk body only contains 64KB memory, all the memory request smaller than 64KB is regarded as small request,
which is directly handled by local heap without additional locking in the global heap and 
the usable memory block in a memory chunk can be classified into two categories: first-allocated block and reusable block,
shown in the figure xx. 
All the blocks starting from the free pointer where first-allocated objects starts or at the free list storing reusable objects is ready to be allocated to users. How to organize the free list will be discussed in the following wear-leveling policy section.

[img] chunk header指向chunk内存块的关系

% how to choose chunk size
\subsubsection{How to choose chunk size}
The memory chunk size is very critical to the performance of wamalloc. 
If the chunk size is too small, the memory block will be used up very soon and frequently communicating with the global heap will greatly decrease the performance.
If the chunk size is too large, lots of memory blocks may remain clean or unused, which leads to a huge memory waste. 
A working method used by many other allocator is to choose chunks of small size to serve small blocks, and chunks of large size to serve large blocks.
The reason why they adopt this method is that there will always be avaliable usable memory blocks no matter what size class it belongs to.
The drawbacks are also obvious.
Since the memory chunk size is different, it increases the complexity of global heap to manage these chunks.
Consequently this will cause the extra time plenalty and the possible memory fragment, which may lead to more physical memory than an application realy needs.

Take above discussions into consideration, we use an uniform memory chunk size for all size class. 
In most cases, memory requests are small allocations, which are naturly guaranteed that there are several usable memory blocks. 
For a special case, if a memory request is 64KB, there is only one block in the entire chunk body, so the allocation policy just view this block as the last remaining block and return it to the application. After that if the application needs a new 64KB memory, a new chunk is allocated to serve this request.
Further, This design gives us several other benifits: 
\begin{enumerate}
    \item Since all memory chunks are of the same size, then an empty chunk can easily be transferred from one size class to another without any particular actions.
The only overhead is to modify the metadata of the chunk, which can be negligible when compared to the non-uniform chunk size schema. 
    \item The uniform memory chunk simplified the design of global heap, which results in a lower time latency when communicating with global heap.
\end{enumerate}

\subsection{Local Heap}

Local heap is maintained by each thread. 
It is set up when a thread issues the first memory request.
Size class related metadata is stored in local heap, every chunk in the local heap can be classified into four categories: Inuse, Waiting, Full, Notavailable. 
The logical view of local heap and its relationship with memory chunk is shown in Figure xxx.

[img] local heap..

\textbf{Inuse chunk}. When an application request a memory block, wamalloc will first find the appropriate size class, then use this class number as index to get the currently using memory chunk. 
All small memory request is served by the inuse chunk.

\textbf{Waiting chunk}. Chunks in the wait list are called waiting chunks. Waiting chunks are the chunks in partially allocated state. 
When application use up the whole memory blocks in the current chunk, chunk of the same class size is a candidate waiting to be chosen as a new inuse chunk.

\textbf{Full chunk}. After several memory requests to a particular size class, a memory chunk may be out of blocks, which is called a full chunk.
No more blocks can be allocated from a chunk in full state , thus the following request will cause the allocator to get usable chunk from waiting chunks.
When a block is freed and the chunk to which the block belongs is in full state, this full chunk is added to the waiting list, becoming a waiting chunk.

\textbf{Notavailable chunk}. Consider all the things we discussed so far, a typical life cycle of a memory chunk could be first used as inuse chunk, then waiting chunk, and back and forth repeatedly. 
For the wear-aware purpose, that is not we expect. 
So we add a wear-count value to each memory chunk and define an allocation threshhold. 
When a chunk is first allocated from global heap, its wear-count value is set to zero.
Every time a block is allocated from a chunk, its wear-count value increases by one. 
If wear-count value of a chunk reaches the predefined allocation threshhold, it is no longer available for allocation, and its state becomes Notavailable. 
When all the blocks in a Notavailable chunk are freed, this chunk is returned to global heap for furthur elaborate wear-leveling policy, which will be discussed in the following subsection.

The state machine of the relationship between different kinds of chunk is shown in figure xxx.

[img] state machine

\subsection{Global Heap}

Global heap maintains the whole memory chunks obtained from operating system. 
All the chunks of each thread are allocated from global heap. 
The logic view of global heap is shown in figure xxx.

[img] global heap

\subsubsection{Classes of allocatable chunks}
From the figure we can conclude that wamalloc first requests a huge continous raw memory and divide it into several chunks ready to be allocated to different threads.
All the chunks starting from the free pointer or at the free list is ready to be allocated, 
just like what we have discussed in block allocation, how to allocate these free chunks is the key to our wear-aware strategy,
which will be discussed in following subsections.
If a chunk is allocated from the free pointer, wamalloc just returns the pointer and then increases this pointer by the size of memory chunk, 
otherwise a chunk is allocated from the free list, a wear-leveling policy must be applied.

\subsubsection{Method of enlarging global heap memory}
Global heap is enlarged via system call(e.g., mmap) if there is no available memory chunk.
Since global heap is shared by all threads, a lock is certainly required, which means a performance descend when lock contention happens.
Thus there exists two different opinions on how to increase the memory space. 
One possible solution aims at economic usage of virtual memory, specifically, increasing the space linearly;
while the other solution aims at reducing the lock contention if possible, for example, increasing the space exponentially. 
In wamaloc, we use the latter solution for two reasons: 
\begin{enumerate}
    \item With the popularization of 64-bit machine, the size of virtual memory far exceeds the real physical memory an application needs.
Hence, it is unimportant that an application may take too much virtual memory. In return we can probably decrease the potential lock contention by accquiring the lock as less as possible.
    \item Almost all of the modern CPUs supports page table mechanism, which means the physical memory is mapped to some virtual address only when an application really needs the physical memory. There is no page mapping at the virtual memory that an application doesn't touch, indicating that no physical memory is wasted.
\end{enumerate}

\subsubsection{How to reap chunks of terminated thread}
After a thread is terminated, there may be several remaining chunks in thread's local heap. 
We need to handle these memory chunks properly.
A typical method used in general-purpose memory allocator is to push these chunks into a global stack(FILO queue)
for the reason that these chunks are probably just used by the terminated thread and they may be in cpu's L1/L2/L3 cache, which is a cache-friendly option to return the chunk already in cache.
However, it is not a possible option for non-volatile memory because wear-leveling must be taken into consideration.
If we continuously serve an application with the hottest memory chunk, memory ceil would be damaged quickly.
More wear-leveling policy will be discussed in the next subsection.

\subsection{wear-leveling policy in different level}

In this subsection we will discuss the wear-leveling policy in different level of wamalloc in detail.

The overall purpose is quite simple: all memory blocks are expected to be allocate evenly.

Traditional method uses first-in-first-out(FIFO) allocation policy(such as queue) or LRU\cite{zhou2009durable}\cite{rodriguez2015write}.
Although the advantage of FIFO is simple and fast, it is not an accurate wear-aware policy.
LRU may be better than FIFO in wear-aware accuracy, but the complexity of maintaining a LRU queue is too high which means a performance drop will happen.

NVMalloc\cite{moraru2013consistent} proposes a method to tackle this problem.
It timestamps every available free memory block to make sure every block is allocated at least in some time interval. NVMalloc implementsit as a don't-allocate list and on every allocation and release, the allocator examines the block at the head of the queue.
If it has been in this list for at least time T(a predefined threshhold), allocator will remove it from list and mark it as available.
Thus, strictly speaking, it is just a modified FIFO and its drawbacks discussed above still exist.
Further more, making a memory block not availale for a time T period will consume more memory spaces. It is obvious since when there is no available block in the interval of T, the allocator need to ask more memory from operating system for new coming requests.


In wamalloc, explicit wear-leveling policy should be applied in two different places. 
We propose a novel hybird wear-leveling method to balance the tradeoff between wear-leveling accuracy and performace.

% wear policy
\subsubsection{wear-leveling policy in block level}
when a thread freed a memory block, this block should be added to the free list of its belonging chunk.
After all first-allocated blocks are used up, a block should be chosen from the free list according to the wear-leveling policy when next allocation happens.
Our target is to allocate memory blocks as evenly as possible.
Thus it is obviously that wamalloc should allocate memory block starting from the free pointer first
because these memory blocks have never been allocated since this chunk is assigned to its local heap.
After a chunk runs out of its first-allocated blocks, wamalloc will search the free list of the chunk to check whether any reusable block is available.
In consideration of allocation latency, no elaborate mechanism is employed for the sake of performance.
We consider free list as a FIFO queue. Queue may not give an accurate allocation, but in return the allocation latency is small.

\subsubsection{wear-leveling policy in chunk level}
It is a common case that global heap need to reap the memory chunk returned from local heap.
Hence there is also a free chunk pool in global heap maintaining all usable chunks. 
Just like the policy adopted in block level, 
when a new thread request a new memory chunk as its in-use chunk,
wamalloc will first allocate memory chunk starting from the free pointer; 
if no available chunk is found, wamalloc will allocate chunk from free chunk pool complied with the following wear-leveling policy.

% hybird method, 异步四叉堆
The best wear-leveling policy should return the least allocated objects so far. 
To the best of our knowledge, the most suitable data structure is a priority queue using allocation time as its key,
and the time complexity of finding the mininum key is $O(1)$, which sounds perfect to our wear-leveling policy.
However, now that it is the best, it is strange that no wear-aware NVM allocator use it.
We think the main reason is that its time complexity of the push operation is $log(n)$ if priority queue is implemented with heaps. 
It will cause an impressive latency when the push operation happens frequently.

In wamalloc, we use two optimizations make the operations of priority queue not to be the bottleneck:
1) 4-heap is used to implement the priority queue since it has a more cpu-friendlier behavior than other implementations.
2) Allocator doestn't move chunks to global pool synchronously, instead, the real operation is taken under the ground asynchronously.

Thus we use our optimized priority queue as the wear-leveling policy used in free chunk pool without performace drop.
% The tradeoff is that it may consume a slight more memory space, which is in an acceptable range 

There are two cases when a thread needs to give memory chunk back to the global heap: 
1) when a thread is terminated, all its memory chunks should be returned back.
2) As we have discussed above, the wear-leveling policy in block level is FIFO, which is not an accurate method.
However, we can achieve a nearly optimal policy using folloing strategy: 
we define a threshhold value \textbf{S} and a allocation time variable \textbf{alloctime} per chunk. 
Everytime a block is allocated from a chunk, its per chunk variable \textbf{alloctime} increases by one.
If \textbf{alloctime} exceed the predefined threshhold \textbf{S}, 
the chunk is no longer available for serving new coming request, and state of the chunk becomes to Notavailable.
When all memory blocks in a Notavailable chunk are freed by a thread, this chunk will be moved to the global heap.
Instead of directly inserting the chunk to the priority queue in the global heap, wamalloc will do it asynchronously.
Specificly, the chunk will be first inserted into a producer-consumer queue, which is a $O(1)$ operations;
a background thread will periodly check the producer-consumer queue to get a returned chunk and insert it to the priority queue.
Since the producer-consumer queue is the global variable shared by all threads, another lock is needed.
A problem may be raised when lock contention happen.
As the evalution section shows, it is not quite frequent that wamalloc inserts a chunk into the producer-consumer queue,
which means the possible lock contention penalty will be amortized so that it won't be the bottleneck of wamalloc.

\subsection{Data Placement In DRAM And NVM}

Metadata in wamalloc can be classified into two different categories: data description and space description.
In this section, we will disscuss which category does the metadatas previously mentioned belong to and how to place them in hybird memory system.
In wamalloc, metadata includes chunk header, local heap and global heap.
Chunk header belongs to data description category, in which it manages the blocks information inside a chunk and some chunk-related data, such as remaining free block counts, size class of current chunk, chunk owner, chunk state, chunk wear-leveling count and so on.
While local heap and global heap belong to space description, it manages where can allocator find the appropriate available chunks.

In tradtional memory allocator, metadata and data are coupled with each other very tightly.
When an allocation/deallocation request comes, there will be plenty of small metadata writes of changing pointer to chain its previous block and next block in order to split large space or merge samll continuous spaces into a large free space.
This access pattern will decrease the lifetime of NVM because of the endurance problem.
Hence it is not what we expect in NVM allocator.

In wamalloc, we keep all metadatas in DRAM except chunk header. 
The reason is that when a thread frees a memory block back to allocator, a memory pointer \textbf{ptr} is passed as argument to wamalloc and its chunk header is easily computed by \textbf{ptr},
otherwise another mechanism would be introduced to remember this relationship, which will certainly cause an extra time cost.
At the meantime, wamalloc keeps the writing frequency of chunk header as few as possibile.

Figure xxx show global view of wamalloc.
[img] global relationship

\subsection{Allocation Algorithm}

Based on the discussion above, we summarize the allocation algorithm in the following pseudo-code.

\begin{algorithm}
\caption{Allocation Algorithm}\label{euclid}
\begin{algorithmic}[1]
\Procedure{MyProcedure}{}

\State $\textit{sc} \gets \text{sizeToClass(}\textit{size}\text{);}$

\If {$\text{isSmallClass}(sc)$}
    \State $\text{lh} \gets \textbf{CurrentLocalHeap}$
    \State $\text{retry:}$
    \State $\text{ch} \gets \text{InUseChunk(}\textit{lh, sc}\text{);}$
    \State $\text{ptr} \gets \text{AllocFromChunk(}\textit{ch}\text{);}$

    \If {$\text{IsEmptyChunk(}\textit{ch}\text{)}$}
        \State $\text{StateOf(}\textit{ch}\text{)} \gets \text{FULL;}$
        \State $\text{FindNewInuseChunkToReplace(}\textit{lh, sc}\text{);}$
        \If {$\text{IsNULL(}\textit{ptr}\text{)}$}
            \State \textbf{goto} \emph{retry};
        \EndIf
    \EndIf

    \State \text{IncreaseWearCount(}\textit{ch, 1}\text{);}
    \If {$\text{WearCount(}\textit{ch}\text{)} \ge \textit{WEAR\_LIMIT}}$
        \State $\text{StateOf(}\textit{ch}\text{)} \gets \text{NotAvailable;}$
        \State $\text{FindNewInuseChunkToReplace(}\textit{lh, sc}\text{);}$
    \EndIf

\Else
    \State $\text{ptr} \gets \text{LargeAlloc(}\textit{size}\text{);}$
\EndIf
\Return $\text{ptr;}$

\EndProcedure
\end{algorithmic}
\end{algorithm}

Critical Path

\subsection{Deallocation Algorithm}


\begin{algorithm}
\caption{Deallocatio nAlgorithm}\label{euclid}
\begin{algorithmic}[1]
\Procedure{MyProcedure}{}

\State $\text{ch} \gets \text{ExtractHeader}\textit{ptr}\text{);}$
\State $\text{lh} \gets \textbf{CurrentLocalHeap}$

\If {$\text{IsLarge(ch)} $}
\State \text{FreeLarge(ch)}
\Else
\State \text{FreeSmall(ch, ptr)}
\EndIf

\EndProcedure
\end{algorithmic}
\end{algorithm}



\section{Global wear levelling}

why? we can’t know the access pattern of a program.

\section{Evaluation}

\section{Related work}


\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

% ensure same length columns on last page (might need two sub-sequent latex runs)
\balance

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{vldb_paper}  % vldb_sample.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

%APPENDIX is optional.
% ****************** APPENDIX **************************************
% Example of an appendix; typically would start on a new page
%pagebreak

\begin{appendix}
You can use an appendix for optional proofs or details of your evaluation which are not absolutely necessary to the core understanding of your paper. 

\section{Final Thoughts on Good Layout}
Please use readable font sizes in the figures and graphs. Avoid tempering with the correct border values, and the spacing (and format) of both text and captions of the PVLDB format (e.g. captions are bold).

At the end, please check for an overall pleasant layout, e.g. by ensuring a readable and logical positioning of any floating figures and tables. Please also check for any line overflows, which are only allowed in extraordinary circumstances (such as wide formulas or URLs where a line wrap would be counterintuitive).

Use the \texttt{balance} package together with a \texttt{\char'134 balance} command at the end of your document to ensure that the last page has balanced (i.e. same length) columns.

\end{appendix}



\end{document}
